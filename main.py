# main.py (ìˆ˜ì • ì™„ë£Œ)
import streamlit as st
import json
import re
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document # Document í´ë˜ìŠ¤ ì„í¬íŠ¸
from utils import (
    extract_text_from_pdf, create_db_from_text,
    generate_summary, generate_ksf, generate_outline,
    handle_chat_interaction, to_excel
)

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í˜ì´ì§€ êµ¬ì„± ---
st.set_page_config(page_title="ë‹¨ê³„ë³„ ì œì•ˆì„œ ë¶„ì„ ë„ìš°ë¯¸", layout="wide")
st.title("ë‹¨ê³„ë³„ ì œì•ˆì„œ ë¶„ì„ ë° í¸ì§‘ ë„ìš°ë¯¸")

# --- 2. ì‚¬ì´ë“œë°” êµ¬ì„± ---
st.sidebar.title("ì„¤ì •")
if "OPENAI_GPT_API_KEY" not in st.secrets or not st.secrets["OPENAI_GPT_API_KEY"].startswith('sk-'):
    st.sidebar.error("OpenAI API í‚¤ë¥¼ .streamlit/secrets.tomlì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()
st.sidebar.success("API í‚¤ ë¡œë“œ ì„±ê³µ")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„í•  RFP PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

# --- 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë¡œì§ ---
# ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”
if uploaded_file and st.session_state.get("uploaded_filename") != uploaded_file.name:
    st.session_state.clear()
    st.session_state.uploaded_filename = uploaded_file.name
    st.session_state.step = 0 # 0: ì‹œì‘ ë‹¨ê³„

if not uploaded_file:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ RFP PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    st.session_state.clear()

# --- 4. ë‹¨ê³„ë³„ ì‹¤í–‰ ë¡œì§ ---
if uploaded_file:
    # --- 1ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
    if st.session_state.step == 0:
        st.info("PDF íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ì‹œì‘í•˜ì„¸ìš”.")
        if st.button("1ë‹¨ê³„: PDF íŒŒì¼ ë‚´ìš© ì¶”ì¶œ"):
            full_text = extract_text_from_pdf(uploaded_file)
            if full_text:
                st.session_state.full_text = full_text
                st.session_state.step = 1 # ë‹¤ìŒ ë‹¨ê³„ë¡œ
                st.rerun()

    # --- 1ë‹¨ê³„ ì™„ë£Œ í›„ & 2ë‹¨ê³„ ì‹œì‘ ì „ ---
    if st.session_state.get("step", 0) >= 1:
        with st.expander("1ë‹¨ê³„: PDF ì¶”ì¶œ ë‚´ìš© í™•ì¸", expanded=(st.session_state.step == 1)):
            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", st.session_state.full_text, height=200)
            st.download_button(
                label="ğŸ“¥ ì¶”ì¶œ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (.txt)",
                data=st.session_state.full_text,
                file_name=f"{uploaded_file.name.split('.')[0]}_extracted.txt",
                mime="text/plain"
            )
            if st.session_state.step == 1:
                st.info("í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì œì•ˆì„œ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                if st.button("2ë‹¨ê³„: ì œì•ˆì„œ ìš”ì•½ ìƒì„±"):
                    with st.spinner("AIê°€ ì œì•ˆì„œë¥¼ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
                        # DB ìƒì„± (ìš”ì•½ ë‹¨ê³„ì—ì„œ ìµœì´ˆ 1íšŒ ì‹¤í–‰)
                        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
                        chunks = text_splitter.split_text(st.session_state.full_text)
                        
                        # LangChainì˜ ê³µì‹ Document ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ doc_chunks ìƒì„±
                        doc_chunks = [Document(page_content=t) for t in chunks]
                        
                        st.session_state.vector_db = create_db_from_text(doc_chunks)
                        
                        # ìš”ì•½ ìƒì„±
                        st.session_state.summary = generate_summary(st.session_state.vector_db)
                        st.session_state.step = 2
                        st.rerun()

    # --- 2ë‹¨ê³„ ì™„ë£Œ í›„ & 3ë‹¨ê³„ ì‹œì‘ ì „ ---
    if st.session_state.get("step", 0) >= 2:
        st.markdown("---")
        st.subheader("2. ì œì•ˆì„œ ìš”ì•½")
        st.markdown(st.session_state.summary)
        if st.session_state.step == 2:
            st.info("ì œì•ˆì„œ ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í•µì‹¬ ì„±ê³µ ìš”ì†Œë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if st.button("3ë‹¨ê³„: í•µì‹¬ ì„±ê³µ ìš”ì†Œ ë¶„ì„"):
                with st.spinner("AIê°€ í•µì‹¬ ì„±ê³µ ìš”ì†Œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.ksf = generate_ksf(st.session_state.vector_db)
                    st.session_state.step = 3
                    st.rerun()

    # --- 3ë‹¨ê³„ ì™„ë£Œ í›„ & 4ë‹¨ê³„ ì‹œì‘ ì „ ---
    if st.session_state.get("step", 0) >= 3:
        st.markdown("---")
        st.subheader("3. í•µì‹¬ ì„±ê³µ ìš”ì†Œ (KSF)")
        st.markdown(st.session_state.ksf)
        if st.session_state.step == 3:
            st.info("í•µì‹¬ ì„±ê³µ ìš”ì†Œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë°œí‘œìë£Œ ëª©ì°¨ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            if st.button("4ë‹¨ê³„: ë°œí‘œìë£Œ ëª©ì°¨ ìƒì„±"):
                with st.spinner("AIê°€ ì°½ì˜ì ì¸ ë°œí‘œìë£Œ ëª©ì°¨ë¥¼ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.presentation_outline = generate_outline(
                        st.session_state.vector_db, st.session_state.summary, st.session_state.ksf
                    )
                    st.session_state.messages = [] # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
                    st.session_state.step = 4
                    st.rerun()

    # --- ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ í›„: ìµœì¢… ê²°ê³¼ë¬¼ ë° ì±„íŒ… UI í‘œì‹œ ---
    if st.session_state.get("step", 0) >= 4:
        st.markdown("---")
        st.success("ëª¨ë“  ë¶„ì„ ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì•„ë˜ ê²°ê³¼ë¬¼ì„ ê²€í† í•˜ê³  ì±„íŒ…ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        col_chat, col_results = st.columns([2, 3])
        
        with col_results:
            st.subheader("ìµœì¢… ê²°ê³¼ë¬¼")
            excel_data = to_excel(st.session_state.summary, st.session_state.ksf, st.session_state.presentation_outline)
            st.download_button(
                label="ğŸ“¥ ì „ì²´ ê²°ê³¼ Excelë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data,
                file_name=f"{uploaded_file.name.split('.')[0]}_analysis.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            tab1, tab2, tab3 = st.tabs(["ì œì•ˆì„œ ìš”ì•½", "í•µì‹¬ ì„±ê³µ ìš”ì†Œ", "ë°œí‘œìë£Œ ëª©ì°¨"])
            with tab1: st.markdown(st.session_state.summary)
            with tab2: st.markdown(st.session_state.ksf)
            with tab3: st.markdown(st.session_state.presentation_outline)

        with col_chat:
            st.subheader("ì§ˆì˜ ë° ìˆ˜ì • ìš”ì²­")
            for message in st.session_state.get("messages", []):
                with st.chat_message(message["role"]): st.markdown(message["content"])
            
            if user_prompt := st.chat_input("ìˆ˜ì •í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
                st.session_state.messages.append({"role": "user", "content": user_prompt})
                with st.chat_message("user"): st.markdown(user_prompt)
                
                with st.chat_message("assistant"):
                    with st.spinner("ìš”ì²­ì„ ë¶„ì„í•˜ê³  ë¬¸ì„œë¥¼ ìˆ˜ì •í•˜ëŠ” ì¤‘..."):
                        # (ì´í•˜ ì±„íŒ… ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
                        response_text = handle_chat_interaction(
                            user_prompt, st.session_state.vector_db, st.session_state.summary,
                            st.session_state.ksf, st.session_state.presentation_outline
                        )
                        try:
                            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                            if not json_match: raise ValueError("ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                            response_data = json.loads(json_match.group(0))
                            target = response_data["target_section"]
                            valid_targets = ["summary", "ksf", "presentation_outline"]
                            if target not in valid_targets: raise ValueError(f"ì˜ëª»ëœ ìˆ˜ì • ëŒ€ìƒ: {target}")
                            st.session_state[target] = response_data["new_content"]
                            success_message = f"âœ… **'{target.upper()}'** ì„¹ì…˜ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
                            st.markdown(success_message)
                            st.session_state.messages.append({"role": "assistant", "content": success_message})
                            st.rerun()
                        except Exception as e:
                            error_message = f"ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\n\nAI ì‘ë‹µ: {response_text}"
                            st.error(error_message)
                            st.session_state.messages.append({"role": "assistant", "content": error_message})
