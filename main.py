# main.py (ë¡¤ë°± ì™„ë£Œ)
import streamlit as st
import json
import re
from utils import generate_initial_results, handle_chat_interaction, to_excel

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í˜ì´ì§€ êµ¬ì„± ---
st.set_page_config(page_title="ëŒ€í™”í˜• ì œì•ˆì„œ ë¶„ì„ ë„ìš°ë¯¸", layout="wide")
st.title("ëŒ€í™”í˜• ì œì•ˆì„œ ë¶„ì„ ë° í¸ì§‘ ë„ìš°ë¯¸")

# --- 2. ì‚¬ì´ë“œë°” êµ¬ì„± ---
st.sidebar.title("ì„¤ì •")
if "OPENAI_GPT_API_KEY" not in st.secrets or not st.secrets["OPENAI_GPT_API_KEY"].startswith('sk-'):
    st.sidebar.error("OpenAI API í‚¤ë¥¼ .streamlit/secrets.tomlì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()
st.sidebar.success("API í‚¤ ë¡œë“œ ì„±ê³µ")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„í•  RFP PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

# --- 3. í•µì‹¬ ë¡œì§: íŒŒì¼ ì²˜ë¦¬ ë° ì´ˆê¸° ë¶„ì„ (í•œë²ˆì— ì‹¤í–‰) ---
if uploaded_file:
    # íŒŒì¼ì´ ë°”ë€Œë©´ session_stateë¥¼ ì´ˆê¸°í™”
    if st.session_state.get("uploaded_filename") != uploaded_file.name:
        st.session_state.clear()
        st.session_state.uploaded_filename = uploaded_file.name

    # ì•„ì§ ì´ˆê¸° ê²°ê³¼ë¬¼ì´ ì—†ë‹¤ë©´ ìƒì„±
    if "summary" not in st.session_state:
        with st.spinner("AIê°€ PDFë¥¼ ë¶„ì„í•˜ê³  ì´ˆê¸° ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            summary, ksf, outline = generate_initial_results(uploaded_file)
            
            if summary and ksf and outline:
                st.session_state.summary = summary
                st.session_state.ksf = ksf
                st.session_state.presentation_outline = outline
                st.session_state.messages = []
                # DBëŠ” ì±„íŒ… ì‹œ í•„ìš”í•˜ë¯€ë¡œ ìºì‹œëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ ì„¸ì…˜ì— ì €ì¥
                # (ì£¼ì˜: DB ì¬ìƒì„±ì„ ë§‰ê¸° ìœ„í•œ íŠ¸ë¦­. generate_initial_resultsê°€ ìºì‹œë˜ì–´ ìˆì–´ë„ DB ê°ì²´ëŠ” ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±ë  ìˆ˜ ìˆìŒ)
                # ì´ ë¶€ë¶„ì€ ê°œì„ ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, í˜„ì¬ êµ¬ì¡°ì—ì„œëŠ” ì±„íŒ… ê¸°ëŠ¥ ìœ ì§€ë¥¼ ìœ„í•´ í•„ìš”.
                # ë” ë‚˜ì€ ë°©ë²•: DB ìƒì„± ë¡œì§ì„ ë¶„ë¦¬í•˜ê³  @st.cache_resourceë¡œ ìºì‹œí•œ ë’¤ mainì—ì„œ ì§ì ‘ í˜¸ì¶œ
                st.sidebar.success("ì´ˆê¸° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ íŒŒì¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                st.stop()
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ RFP PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    st.session_state.clear()

# --- 4. ë©”ì¸ í™”ë©´ UI ë Œë”ë§ (ê²°ê³¼ ìƒì„± í›„) ---
if "summary" in st.session_state:
    col_chat, col_results = st.columns([2, 3])
    
    with col_results:
        st.subheader("ìµœì¢… ê²°ê³¼ë¬¼")
        excel_data = to_excel(st.session_state.summary, st.session_state.ksf, st.session_state.presentation_outline)
        st.download_button(
            label="ğŸ“¥ ì „ì²´ ê²°ê³¼ Excelë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data,
            file_name=f"{uploaded_file.name.split('.')[0]}_analysis.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        tab1, tab2, tab3 = st.tabs(["ì œì•ˆì„œ ìš”ì•½", "í•µì‹¬ ì„±ê³µ ìš”ì†Œ", "ë°œí‘œìë£Œ ëª©ì°¨"])
        with tab1: st.markdown(st.session_state.summary)
        with tab2: st.markdown(st.session_state.ksf)
        with tab3: st.markdown(st.session_state.presentation_outline)

    with col_chat:
        st.subheader("ì§ˆì˜ ë° ìˆ˜ì • ìš”ì²­")
        for message in st.session_state.get("messages", []):
            with st.chat_message(message["role"]): st.markdown(message["content"])
        
        if user_prompt := st.chat_input("ìˆ˜ì •í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": user_prompt})
            with st.chat_message("user"): st.markdown(user_prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("ìš”ì²­ì„ ë¶„ì„í•˜ê³  ë¬¸ì„œë¥¼ ìˆ˜ì •í•˜ëŠ” ì¤‘..."):
                    # ì±„íŒ…ì„ ìœ„í•œ DB ì¬ìƒì„± (ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ í˜„ì¬ êµ¬ì¡°ì—ì„œ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•)
                    from langchain.text_splitter import RecursiveCharacterTextSplitter
                    from langchain_core.documents import Document
                    import fitz

                    file_bytes = uploaded_file.getvalue()
                    doc = fitz.open(stream=file_bytes, filetype="pdf")
                    all_text = [page.get_text() for page in doc]
                    doc.close()
                    full_text = "\n\n".join(all_text)
                    
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
                    chunks = text_splitter.split_text(full_text)
                    doc_chunks = [Document(page_content=t) for t in chunks]
                    
                    from langchain_openai import OpenAIEmbeddings
                    from langchain_community.vectorstores import FAISS
                    embeddings = OpenAIEmbeddings(api_key=st.secrets["OPENAI_GPT_API_KEY"])
                    vector_db = FAISS.from_documents(doc_chunks, embeddings)

                    response_text = handle_chat_interaction(
                        user_prompt, vector_db, st.session_state.summary,
                        st.session_state.ksf, st.session_state.presentation_outline
                    )
                    try:
                        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                        if not json_match: raise ValueError("ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        response_data = json.loads(json_match.group(0))
                        target = response_data["target_section"]
                        valid_targets = ["summary", "ksf", "presentation_outline"]
                        if target not in valid_targets: raise ValueError(f"ì˜ëª»ëœ ìˆ˜ì • ëŒ€ìƒ: {target}")
                        st.session_state[target] = response_data["new_content"]
                        success_message = f"âœ… **'{target.upper()}'** ì„¹ì…˜ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
                        st.markdown(success_message)
                        st.session_state.messages.append({"role": "assistant", "content": success_message})
                        st.rerun()
                    except Exception as e:
                        error_message = f"ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\n\nAI ì‘ë‹µ: {response_text}"
                        st.error(error_message)
                        st.session_state.messages.append({"role": "assistant", "content": error_message})
